{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e647a2a5-964c-4ae6-83d0-9652c062ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim import Adam\n",
    "from torchvision.transforms import v2\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23177055-1c5f-4d0e-abd0-3b96048912bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd50d47-60e3-495e-afb5-80549294c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_train_paths = sorted(glob.glob(\"../data/DIV2K/DIV2K_train_HR/*.png\"))\n",
    "X2_train_paths = sorted(glob.glob(\"../data/DIV2K/DIV2K_train_LR_bicubic/X2/*.png\"))\n",
    "X4_train_paths = sorted(glob.glob(\"../data/DIV2K/DIV2K_train_LR_bicubic/X4/*.png\"))\n",
    "X8_train_paths = sorted(glob.glob(\"../data/DIV2K/DIV2K_train_LR_bicubic/X8/*.png\"))\n",
    "X16_train_paths = sorted(glob.glob(\"../data/DIV2K/DIV2K_train_LR_bicubic/X16/*.png\"))\n",
    "X32_train_paths = sorted(glob.glob(\"../data/DIV2K/DIV2K_train_LR_bicubic/X32/*.png\"))\n",
    "X64_train_paths = sorted(glob.glob(\"../data/DIV2K/DIV2K_train_LR_bicubic/X64/*.png\"))\n",
    "\n",
    "HR_valid_paths = sorted(glob.glob(\"../data/DIV2K/DIV2K_valid_HR/*.png\"))\n",
    "X2_valid_paths = sorted(glob.glob(\"../data/DIV2K/DIV2K_valid_LR_bicubic/X2/*.png\"))\n",
    "X4_valid_paths = sorted(glob.glob(\"../data/DIV2K/DIV2K_valid_LR_bicubic/X4/*.png\"))\n",
    "X8_valid_paths = sorted(glob.glob(\"../data/DIV2K/DIV2K_valid_LR_bicubic/X8/*.png\"))\n",
    "X16_valid_paths = sorted(glob.glob(\"../data/DIV2K/DIV2K_valid_LR_bicubic/X16/*.png\"))\n",
    "X32_valid_paths = sorted(glob.glob(\"../data/DIV2K/DIV2K_valid_LR_bicubic/X32/*.png\"))\n",
    "X64_valid_paths = sorted(glob.glob(\"../data/DIV2K/DIV2K_valid_LR_bicubic/X64/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58025974-ea12-43c4-ab10-216e56f41616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential()\n",
    "        for i in range(1,5):\n",
    "            self.blocks.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(i * 64, 64, 3, stride=1, padding='same'),\n",
    "                    nn.LeakyReLU()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.blocks.append(nn.Conv2d(5 * 64, 64, 3, stride=1, padding='same'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.blocks[0](x)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x2 = self.blocks[1](x)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x3 = self.blocks[2](x)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x4 = self.blocks[3](x)\n",
    "        x = torch.cat([x, x4], dim=1)\n",
    "        return self.blocks[4](x)\n",
    "        \n",
    "class ESRGAN(nn.Module):\n",
    "    def __init__(self, n: int):\n",
    "        \"\"\"\n",
    "        Enhanced Deep Residual Network with Residual in Residual Dense Block a.k.a.\n",
    "        Enhanced Super Resolution Generative Adversarial Networks\n",
    "        Args:\n",
    "            n: scaling factor\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.DIV2K_RGB = torch.tensor([0.44882884613943946, 0.43713809810624193, 0.4040371984052683]).view(1, 3, 1, 1).to(device)\n",
    "        \n",
    "        self.expand = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 9, stride=1, padding='same'),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        self.residual_blocks = nn.Sequential()\n",
    "        for _ in range(23):\n",
    "            self.residual_blocks.append(DenseBlock())\n",
    "\n",
    "        self.residual_blocks.append(nn.Conv2d(64, 64, 3, stride=1, padding='same'))\n",
    "\n",
    "        self.upscaling_head = nn.Sequential()\n",
    "        for _ in range(int(math.log2(n))):\n",
    "            self.upscaling_head.append(nn.Conv2d(64, 256, 3, stride=1, padding='same'))\n",
    "            self.upscaling_head.append(nn.PixelShuffle(2))\n",
    "            self.upscaling_head.append(nn.PReLU())\n",
    "            \n",
    "        self.upscaling_head.append(nn.Conv2d(64, 64, 9, stride=1, padding='same'))\n",
    "        self.upscaling_head.append(nn.Conv2d(64, 3, 9, stride=1, padding='same'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.expand(x-self.DIV2K_RGB)\n",
    "        xp = x.clone()\n",
    "        for i in range(23):\n",
    "            xp = xp + 0.2 * self.residual_blocks[i](xp)\n",
    "\n",
    "        x = x + 0.2 * self.residual_blocks[23](xp)\n",
    "        return self.upscaling_head(x) + self.DIV2K_RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b40ab11e-8e41-4836-8727-1350ff665a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESRGAN_Dataset(Dataset):\n",
    "    def __init__(self, target_paths: list[str], scale: int, ram_limit_gb: float = 2.0):\n",
    "        self.crop_size = scale * 48\n",
    "        self.scale = scale\n",
    "\n",
    "        self.rotations = [0, 90, 180, 270]\n",
    "        self.transforms = v2.Compose([\n",
    "            v2.PILToTensor(),\n",
    "            v2.Lambda(lambda x: (x / 255.0))\n",
    "        ])\n",
    "\n",
    "        self.preloaded = {}\n",
    "        self.paths = target_paths\n",
    "\n",
    "        total_ram_used = 0\n",
    "        for i, path in enumerate(tqdm(target_paths, desc=\"Preloading images\")):\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            total_ram_used += img.width * img.height * 3 / (1024 ** 3)  # ~size in GB\n",
    "\n",
    "            if total_ram_used < ram_limit_gb:\n",
    "                self.preloaded[i] = img\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx in self.preloaded:\n",
    "            target = self.preloaded[idx]\n",
    "        else:\n",
    "            target = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "\n",
    "        target = self.random_crop(target, self.crop_size)\n",
    "        inp = target.resize((target.width // self.scale, target.height // self.scale), Image.BICUBIC)\n",
    "        \n",
    "        rotation =  random.choice(self.rotations)\n",
    "        if rotation != 0:\n",
    "            inp = v2.functional.rotate(inp, rotation)\n",
    "            target = v2.functional.rotate(target, rotation)\n",
    "        if random.randint(0, 1):\n",
    "            inp = v2.functional.horizontal_flip(inp)\n",
    "            target = v2.functional.horizontal_flip(target)\n",
    "            \n",
    "        return self.transforms(inp), self.transforms(target)\n",
    "\n",
    "    def random_crop(self, img, size):\n",
    "        w, h = img.size\n",
    "        if w < size or h < size:\n",
    "            img = img.resize((size, size), Image.BICUBIC)\n",
    "        x = random.randint(0, w - size)\n",
    "        y = random.randint(0, h - size)\n",
    "        return img.crop((x, y, x + size, y + size))\n",
    "\n",
    "    def set_scale(self, scale: int):\n",
    "        self.scale = scale\n",
    "\n",
    "    def set_crop_size(self, crop_size: int):\n",
    "        self.crop_size = crop_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1906f47e-ddec-4c9a-be1c-41a901dac152",
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr = PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
    "ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "lpips = LearnedPerceptualImagePatchSimilarity(normalize=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58cf537d-72c3-45c6-b97c-c58219c51dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    v2.Lambda(lambda x: x / 255.0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd85a078-f328-47ef-afcd-fbfaaa4e6b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(model: nn.Module, target_ds: list[str], scale: int):\n",
    "    transform_target = v2.Compose([\n",
    "        v2.PILToTensor(),\n",
    "        v2.Lambda(lambda x: x/255.0)\n",
    "    ])\n",
    "\n",
    "    transform_input = v2.Compose([\n",
    "        v2.PILToTensor(),\n",
    "        v2.Lambda(lambda x: (x / 255.0))\n",
    "    ])\n",
    "\n",
    "    psnr_acc = 0\n",
    "    ssim_acc = 0\n",
    "    lpips_acc = 0\n",
    "    failed_lpips = 0\n",
    "\n",
    "    for i in tqdm(range(len(target_ds)), leave=False):\n",
    "        target_image = Image.open(target_ds[i]).convert(\"RGB\")\n",
    "        w, h = target_image.size\n",
    "\n",
    "        w -= w % scale\n",
    "        h -= h % scale\n",
    "        target_image = target_image.crop((0, 0, w, h))\n",
    "        \n",
    "        lowres = target_image.resize((w // scale, h // scale), resample=Image.BICUBIC)\n",
    "        input_tensor = transform_input(lowres).unsqueeze(0).to(device)\n",
    "        target_tensor = transform_target(target_image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            sr = model(input_tensor).clamp(0, 1)\n",
    "\n",
    "        psnr_acc += psnr(sr, target_tensor).item()\n",
    "        ssim_acc += ssim(sr, target_tensor).item()\n",
    "        \n",
    "        # There are 2 images that cause lpips to fail\n",
    "        try:\n",
    "            x = lpips(sr, target_tensor).cpu().item()\n",
    "            if np.isnan(x):\n",
    "                failed_lpips += 1\n",
    "                continue\n",
    "                \n",
    "            lpips_acc += x\n",
    "        except:\n",
    "            failed_lpips += 1\n",
    "\n",
    "    lpips_acc /= len(target_ds) - failed_lpips\n",
    "    psnr_acc /= len(target_ds)\n",
    "    ssim_acc /= len(target_ds)\n",
    "    return psnr_acc, ssim_acc, lpips_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e59803-6b82-4188-aaed-96f3151946f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, dataloader, optimizer, loss_fn, scaler):\n",
    "    avg_psnr = 0\n",
    "    avg_ssim = 0\n",
    "    model.train()\n",
    "\n",
    "    for batch, target in dataloader:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        batch, target = batch.to(device), target.to(device)\n",
    "\n",
    "        with autocast('cuda'):\n",
    "            logits = model(batch)\n",
    "            loss = loss_fn(logits, target)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        logits = logits.clamp(0.0, 1.0)\n",
    "        target = target.clamp(0.0, 1.0)\n",
    "        \n",
    "        avg_psnr += psnr(logits, target).item()\n",
    "        avg_ssim += ssim(logits, target).item()\n",
    "        \n",
    "    avg_psnr /= len(dataloader)\n",
    "    avg_ssim /= len(dataloader)\n",
    "    return avg_psnr, avg_ssim\n",
    "\n",
    "def valid_step(model, dataloader, loss_fn):\n",
    "    avg_psnr = 0\n",
    "    avg_ssim = 0\n",
    "    avg_lpips = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, target in dataloader:\n",
    "            batch, target = batch.to(device), target.to(device)\n",
    "\n",
    "            logits = model(batch)\n",
    "            \n",
    "            logits = logits.clamp(0.0, 1.0)\n",
    "            target = target.clamp(0.0, 1.0)\n",
    "            \n",
    "            avg_psnr += psnr(logits, target).item()\n",
    "            avg_ssim += ssim(logits, target).item()\n",
    "            avg_lpips += lpips(logits, target).item()\n",
    "\n",
    "    avg_psnr /= len(dataloader)\n",
    "    avg_ssim /= len(dataloader)\n",
    "    avg_lpips /= len(dataloader)\n",
    "\n",
    "        \n",
    "    return avg_psnr, avg_ssim, avg_lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb828c7f-a76c-4e49-86c0-b162b5b96e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, valid_dl, optimizer, scheduler: StepLR, loss_fn, epochs, start_checkpoint=None):\n",
    "    os.makedirs('../tmp_model_checkpoints', exist_ok=True)\n",
    "    counter = 0 # count epochs without printing training stats\n",
    "    scaler = GradScaler('cuda')\n",
    "    \n",
    "    if start_checkpoint:\n",
    "        start_epoch = start_checkpoint['epoch']\n",
    "        best_psnr = start_checkpoint['best_psnr']\n",
    "        best_ssim = start_checkpoint['best_ssim']\n",
    "        best_lpips = start_checkpoint['best_lpips']\n",
    "        scaler.load_state_dict(start_checkpoint['scaler_state_dict'])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        best_psnr = 0\n",
    "        best_ssim = 0\n",
    "        best_lpips = float('inf')\n",
    "        \n",
    "    log_freq = (epochs - start_epoch) // 20 # how often to print stats when no progress is made\n",
    "    \n",
    "    for epoch in tqdm(range(start_epoch, epochs), desc=\"Epochs\"):\n",
    "        counter += 1\n",
    "        train_psnr, train_ssim = train_step(\n",
    "            model,\n",
    "            train_dl,\n",
    "            optimizer,\n",
    "            loss_fn,\n",
    "            scaler\n",
    "        )\n",
    "\n",
    "        valid_psnr, valid_ssim, valid_lpips = valid_step(\n",
    "            model,\n",
    "            valid_dl,\n",
    "            loss_fn,\n",
    "        )\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        progress = False\n",
    "        \n",
    "        if valid_psnr > best_psnr:\n",
    "            progress = True\n",
    "            best_psnr = valid_psnr\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'best_psnr': best_psnr,\n",
    "                'best_ssim': best_ssim,\n",
    "                'best_lpips': best_lpips,\n",
    "                'model_state_dict': model._orig_mod.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, f'../tmp_model_checkpoints/best_psnr.pth')\n",
    "\n",
    "        if valid_ssim > best_ssim:\n",
    "            progress = True\n",
    "            best_ssim = valid_ssim\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'best_psnr': best_psnr,\n",
    "                'best_ssim': best_ssim,\n",
    "                'best_lpips': best_lpips,\n",
    "                'model_state_dict': model._orig_mod.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, f'../tmp_model_checkpoints/best_ssim.pth')\n",
    "\n",
    "        if valid_lpips < best_lpips:\n",
    "            progress = True\n",
    "            best_lpips = valid_lpips\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'best_psnr': best_psnr,\n",
    "                'best_ssim': best_ssim,\n",
    "                'best_lpips': best_lpips,\n",
    "                'model_state_dict': model._orig_mod.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, f'../tmp_model_checkpoints/best_lpips.pth')\n",
    "\n",
    "        if epoch == epochs-1:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'best_psnr': best_psnr,\n",
    "                'best_ssim': best_ssim,\n",
    "                'best_lpips': best_lpips,\n",
    "                'model_state_dict': model._orig_mod.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, f'../tmp_model_checkpoints/last.pth')\n",
    "            \n",
    "        if progress or counter >= log_freq:\n",
    "            counter = 0\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} | \"\n",
    "                f\"learning rate: {scheduler.get_last_lr()[0]:.6f} | \"\n",
    "                f\"[train] PSNR: {train_psnr:.4f} | \"\n",
    "                f\"[train] SSIM: {train_ssim:.4f} | \"\n",
    "                f\"[valid] PSNR: {valid_psnr:.4f} | \"\n",
    "                f\"[valid] SSIM: {valid_ssim:.4f} | \"\n",
    "                f\"[valid] LPIPS: {valid_lpips:.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1d30c-d8c7-44bc-9b2d-b52fec1c1ac0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46bd1c5a-0c7e-4784-85ed-8707762af624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2fc7329d5024fc5bca7004e8739081f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preloading images:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_ds = ESRGAN_Dataset(HR_valid_paths, 2, ram_limit_gb=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af535df3-cda9-4118-afa6-f891429cc15e",
   "metadata": {},
   "source": [
    "### Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9329bcb-0329-4f68-a87f-653a164b1b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b63fb9e4114151ae3a3a87f5686ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preloading images:   0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = ESRGAN_Dataset(HR_train_paths, 2, ram_limit_gb=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8bdee25-94c2-441b-b2b5-5b692ffd6afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8df2db95e1435294b0fef1105021c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | learning rate: 0.000200 | [train] PSNR: 18.9776 | [train] SSIM: 0.5087 | [valid] PSNR: 21.0153 | [valid] SSIM: 0.5850 | [valid] LPIPS: 0.6051\n",
      "Epoch: 2 | learning rate: 0.000200 | [train] PSNR: 21.6945 | [train] SSIM: 0.6089 | [valid] PSNR: 23.1694 | [valid] SSIM: 0.6550 | [valid] LPIPS: 0.4928\n",
      "Epoch: 3 | learning rate: 0.000200 | [train] PSNR: 23.3442 | [train] SSIM: 0.6838 | [valid] PSNR: 24.1877 | [valid] SSIM: 0.7099 | [valid] LPIPS: 0.4014\n",
      "Epoch: 4 | learning rate: 0.000200 | [train] PSNR: 24.1489 | [train] SSIM: 0.7295 | [valid] PSNR: 23.8524 | [valid] SSIM: 0.7246 | [valid] LPIPS: 0.3486\n",
      "Epoch: 5 | learning rate: 0.000200 | [train] PSNR: 25.2312 | [train] SSIM: 0.7704 | [valid] PSNR: 25.0179 | [valid] SSIM: 0.7854 | [valid] LPIPS: 0.3076\n",
      "Epoch: 6 | learning rate: 0.000200 | [train] PSNR: 25.6468 | [train] SSIM: 0.7944 | [valid] PSNR: 26.5587 | [valid] SSIM: 0.8283 | [valid] LPIPS: 0.2407\n",
      "Epoch: 7 | learning rate: 0.000200 | [train] PSNR: 26.4225 | [train] SSIM: 0.8130 | [valid] PSNR: 26.7770 | [valid] SSIM: 0.8368 | [valid] LPIPS: 0.2011\n",
      "Epoch: 8 | learning rate: 0.000200 | [train] PSNR: 26.8638 | [train] SSIM: 0.8343 | [valid] PSNR: 27.9270 | [valid] SSIM: 0.8474 | [valid] LPIPS: 0.1854\n",
      "Epoch: 9 | learning rate: 0.000200 | [train] PSNR: 27.3707 | [train] SSIM: 0.8463 | [valid] PSNR: 27.5931 | [valid] SSIM: 0.8444 | [valid] LPIPS: 0.1683\n",
      "Epoch: 10 | learning rate: 0.000200 | [train] PSNR: 27.4811 | [train] SSIM: 0.8547 | [valid] PSNR: 27.9451 | [valid] SSIM: 0.8540 | [valid] LPIPS: 0.1457\n",
      "Epoch: 12 | learning rate: 0.000200 | [train] PSNR: 27.7615 | [train] SSIM: 0.8606 | [valid] PSNR: 28.6415 | [valid] SSIM: 0.8665 | [valid] LPIPS: 0.1197\n",
      "Epoch: 13 | learning rate: 0.000200 | [train] PSNR: 27.9199 | [train] SSIM: 0.8627 | [valid] PSNR: 28.2077 | [valid] SSIM: 0.8681 | [valid] LPIPS: 0.1235\n",
      "Epoch: 14 | learning rate: 0.000200 | [train] PSNR: 27.9896 | [train] SSIM: 0.8680 | [valid] PSNR: 28.3026 | [valid] SSIM: 0.8710 | [valid] LPIPS: 0.1197\n",
      "Epoch: 15 | learning rate: 0.000200 | [train] PSNR: 28.3190 | [train] SSIM: 0.8733 | [valid] PSNR: 27.1419 | [valid] SSIM: 0.8628 | [valid] LPIPS: 0.1171\n",
      "Epoch: 16 | learning rate: 0.000200 | [train] PSNR: 28.0158 | [train] SSIM: 0.8715 | [valid] PSNR: 28.5082 | [valid] SSIM: 0.8736 | [valid] LPIPS: 0.1206\n",
      "Epoch: 17 | learning rate: 0.000200 | [train] PSNR: 28.3119 | [train] SSIM: 0.8735 | [valid] PSNR: 28.8009 | [valid] SSIM: 0.8804 | [valid] LPIPS: 0.1115\n",
      "Epoch: 18 | learning rate: 0.000200 | [train] PSNR: 28.5561 | [train] SSIM: 0.8794 | [valid] PSNR: 27.8582 | [valid] SSIM: 0.8698 | [valid] LPIPS: 0.1112\n",
      "Epoch: 21 | learning rate: 0.000200 | [train] PSNR: 28.3302 | [train] SSIM: 0.8809 | [valid] PSNR: 28.5927 | [valid] SSIM: 0.8934 | [valid] LPIPS: 0.0999\n",
      "Epoch: 23 | learning rate: 0.000200 | [train] PSNR: 29.2643 | [train] SSIM: 0.8890 | [valid] PSNR: 29.6017 | [valid] SSIM: 0.8917 | [valid] LPIPS: 0.1036\n",
      "Epoch: 24 | learning rate: 0.000200 | [train] PSNR: 28.9793 | [train] SSIM: 0.8936 | [valid] PSNR: 29.6169 | [valid] SSIM: 0.8856 | [valid] LPIPS: 0.1034\n",
      "Epoch: 30 | learning rate: 0.000200 | [train] PSNR: 29.0443 | [train] SSIM: 0.8917 | [valid] PSNR: 29.7758 | [valid] SSIM: 0.8881 | [valid] LPIPS: 0.0997\n",
      "Epoch: 32 | learning rate: 0.000200 | [train] PSNR: 28.9550 | [train] SSIM: 0.8888 | [valid] PSNR: 29.4697 | [valid] SSIM: 0.9010 | [valid] LPIPS: 0.0991\n",
      "Epoch: 34 | learning rate: 0.000200 | [train] PSNR: 29.2115 | [train] SSIM: 0.8952 | [valid] PSNR: 30.0076 | [valid] SSIM: 0.9013 | [valid] LPIPS: 0.0882\n",
      "Epoch: 39 | learning rate: 0.000200 | [train] PSNR: 29.2068 | [train] SSIM: 0.8946 | [valid] PSNR: 29.8550 | [valid] SSIM: 0.9055 | [valid] LPIPS: 0.0768\n",
      "Epoch: 48 | learning rate: 0.000200 | [train] PSNR: 29.7553 | [train] SSIM: 0.9033 | [valid] PSNR: 30.1491 | [valid] SSIM: 0.9142 | [valid] LPIPS: 0.0699\n",
      "Epoch: 49 | learning rate: 0.000200 | [train] PSNR: 30.2616 | [train] SSIM: 0.9098 | [valid] PSNR: 30.3864 | [valid] SSIM: 0.9125 | [valid] LPIPS: 0.0833\n",
      "Epoch: 53 | learning rate: 0.000200 | [train] PSNR: 30.0239 | [train] SSIM: 0.9084 | [valid] PSNR: 30.3941 | [valid] SSIM: 0.9003 | [valid] LPIPS: 0.0692\n",
      "Epoch: 56 | learning rate: 0.000200 | [train] PSNR: 30.3060 | [train] SSIM: 0.9131 | [valid] PSNR: 30.7998 | [valid] SSIM: 0.9017 | [valid] LPIPS: 0.0734\n",
      "Epoch: 57 | learning rate: 0.000200 | [train] PSNR: 30.3376 | [train] SSIM: 0.9105 | [valid] PSNR: 30.8050 | [valid] SSIM: 0.9085 | [valid] LPIPS: 0.0795\n",
      "Epoch: 63 | learning rate: 0.000200 | [train] PSNR: 29.9650 | [train] SSIM: 0.9090 | [valid] PSNR: 30.9107 | [valid] SSIM: 0.9190 | [valid] LPIPS: 0.0715\n",
      "Epoch: 64 | learning rate: 0.000200 | [train] PSNR: 29.9905 | [train] SSIM: 0.9100 | [valid] PSNR: 30.7286 | [valid] SSIM: 0.9119 | [valid] LPIPS: 0.0688\n",
      "Epoch: 66 | learning rate: 0.000200 | [train] PSNR: 30.0532 | [train] SSIM: 0.9102 | [valid] PSNR: 30.3580 | [valid] SSIM: 0.9211 | [valid] LPIPS: 0.0646\n",
      "Epoch: 74 | learning rate: 0.000200 | [train] PSNR: 30.1026 | [train] SSIM: 0.9088 | [valid] PSNR: 30.9923 | [valid] SSIM: 0.9214 | [valid] LPIPS: 0.0674\n",
      "Epoch: 81 | learning rate: 0.000200 | [train] PSNR: 30.1687 | [train] SSIM: 0.9117 | [valid] PSNR: 31.3026 | [valid] SSIM: 0.9140 | [valid] LPIPS: 0.0718\n",
      "Epoch: 82 | learning rate: 0.000200 | [train] PSNR: 30.6170 | [train] SSIM: 0.9179 | [valid] PSNR: 30.5363 | [valid] SSIM: 0.9199 | [valid] LPIPS: 0.0621\n",
      "Epoch: 98 | learning rate: 0.000200 | [train] PSNR: 30.5277 | [train] SSIM: 0.9158 | [valid] PSNR: 31.1149 | [valid] SSIM: 0.9216 | [valid] LPIPS: 0.0602\n",
      "Epoch: 100 | learning rate: 0.000200 | [train] PSNR: 30.5042 | [train] SSIM: 0.9149 | [valid] PSNR: 31.4012 | [valid] SSIM: 0.9254 | [valid] LPIPS: 0.0572\n",
      "Epoch: 105 | learning rate: 0.000200 | [train] PSNR: 30.4799 | [train] SSIM: 0.9183 | [valid] PSNR: 31.7935 | [valid] SSIM: 0.9203 | [valid] LPIPS: 0.0667\n",
      "Epoch: 106 | learning rate: 0.000200 | [train] PSNR: 30.6714 | [train] SSIM: 0.9168 | [valid] PSNR: 31.8173 | [valid] SSIM: 0.9250 | [valid] LPIPS: 0.0594\n",
      "Epoch: 108 | learning rate: 0.000200 | [train] PSNR: 30.6378 | [train] SSIM: 0.9167 | [valid] PSNR: 31.4918 | [valid] SSIM: 0.9268 | [valid] LPIPS: 0.0661\n",
      "Epoch: 119 | learning rate: 0.000200 | [train] PSNR: 30.7111 | [train] SSIM: 0.9188 | [valid] PSNR: 32.1642 | [valid] SSIM: 0.9251 | [valid] LPIPS: 0.0693\n",
      "Epoch: 129 | learning rate: 0.000200 | [train] PSNR: 30.5867 | [train] SSIM: 0.9207 | [valid] PSNR: 32.1819 | [valid] SSIM: 0.9245 | [valid] LPIPS: 0.0621\n",
      "Epoch: 132 | learning rate: 0.000200 | [train] PSNR: 30.6903 | [train] SSIM: 0.9204 | [valid] PSNR: 32.0735 | [valid] SSIM: 0.9271 | [valid] LPIPS: 0.0585\n",
      "Epoch: 143 | learning rate: 0.000200 | [train] PSNR: 30.5393 | [train] SSIM: 0.9189 | [valid] PSNR: 32.0650 | [valid] SSIM: 0.9283 | [valid] LPIPS: 0.0613\n",
      "Epoch: 159 | learning rate: 0.000200 | [train] PSNR: 31.0620 | [train] SSIM: 0.9228 | [valid] PSNR: 31.6018 | [valid] SSIM: 0.9290 | [valid] LPIPS: 0.0605\n",
      "Epoch: 161 | learning rate: 0.000200 | [train] PSNR: 30.8276 | [train] SSIM: 0.9202 | [valid] PSNR: 32.6909 | [valid] SSIM: 0.9289 | [valid] LPIPS: 0.0651\n",
      "Epoch: 166 | learning rate: 0.000200 | [train] PSNR: 30.8711 | [train] SSIM: 0.9216 | [valid] PSNR: 31.3147 | [valid] SSIM: 0.9239 | [valid] LPIPS: 0.0569\n",
      "Epoch: 183 | learning rate: 0.000200 | [train] PSNR: 31.3067 | [train] SSIM: 0.9258 | [valid] PSNR: 31.6424 | [valid] SSIM: 0.9248 | [valid] LPIPS: 0.0568\n",
      "Epoch: 184 | learning rate: 0.000200 | [train] PSNR: 31.0786 | [train] SSIM: 0.9240 | [valid] PSNR: 32.4899 | [valid] SSIM: 0.9300 | [valid] LPIPS: 0.0599\n",
      "Epoch: 228 | learning rate: 0.000200 | [train] PSNR: 31.0426 | [train] SSIM: 0.9246 | [valid] PSNR: 31.1720 | [valid] SSIM: 0.9298 | [valid] LPIPS: 0.0545\n",
      "Epoch: 252 | learning rate: 0.000200 | [train] PSNR: 31.2963 | [train] SSIM: 0.9251 | [valid] PSNR: 31.7748 | [valid] SSIM: 0.9323 | [valid] LPIPS: 0.0593\n",
      "Epoch: 266 | learning rate: 0.000200 | [train] PSNR: 31.6952 | [train] SSIM: 0.9250 | [valid] PSNR: 31.4671 | [valid] SSIM: 0.9285 | [valid] LPIPS: 0.0543\n",
      "Epoch: 301 | learning rate: 0.000200 | [train] PSNR: 31.2054 | [train] SSIM: 0.9275 | [valid] PSNR: 31.7583 | [valid] SSIM: 0.9295 | [valid] LPIPS: 0.0539\n",
      "Epoch: 304 | learning rate: 0.000200 | [train] PSNR: 31.2122 | [train] SSIM: 0.9262 | [valid] PSNR: 32.2234 | [valid] SSIM: 0.9397 | [valid] LPIPS: 0.0528\n",
      "Epoch: 326 | learning rate: 0.000200 | [train] PSNR: 31.1977 | [train] SSIM: 0.9289 | [valid] PSNR: 31.7662 | [valid] SSIM: 0.9311 | [valid] LPIPS: 0.0522\n",
      "Epoch: 334 | learning rate: 0.000200 | [train] PSNR: 31.5364 | [train] SSIM: 0.9288 | [valid] PSNR: 32.3913 | [valid] SSIM: 0.9356 | [valid] LPIPS: 0.0483\n",
      "Epoch: 347 | learning rate: 0.000200 | [train] PSNR: 31.3537 | [train] SSIM: 0.9294 | [valid] PSNR: 32.5688 | [valid] SSIM: 0.9402 | [valid] LPIPS: 0.0508\n",
      "Epoch: 447 | learning rate: 0.000100 | [train] PSNR: 31.4906 | [train] SSIM: 0.9306 | [valid] PSNR: 32.0184 | [valid] SSIM: 0.9286 | [valid] LPIPS: 0.0614\n",
      "Epoch: 449 | learning rate: 0.000100 | [train] PSNR: 31.8488 | [train] SSIM: 0.9333 | [valid] PSNR: 32.8701 | [valid] SSIM: 0.9346 | [valid] LPIPS: 0.0593\n",
      "Epoch: 453 | learning rate: 0.000100 | [train] PSNR: 31.4033 | [train] SSIM: 0.9327 | [valid] PSNR: 32.9866 | [valid] SSIM: 0.9400 | [valid] LPIPS: 0.0528\n",
      "Epoch: 459 | learning rate: 0.000100 | [train] PSNR: 31.5678 | [train] SSIM: 0.9307 | [valid] PSNR: 32.3018 | [valid] SSIM: 0.9404 | [valid] LPIPS: 0.0550\n",
      "Epoch: 498 | learning rate: 0.000100 | [train] PSNR: 31.6169 | [train] SSIM: 0.9325 | [valid] PSNR: 33.0211 | [valid] SSIM: 0.9434 | [valid] LPIPS: 0.0504\n",
      "Epoch: 575 | learning rate: 0.000100 | [train] PSNR: 31.8246 | [train] SSIM: 0.9329 | [valid] PSNR: 33.0367 | [valid] SSIM: 0.9416 | [valid] LPIPS: 0.0513\n",
      "Epoch: 624 | learning rate: 0.000100 | [train] PSNR: 31.9995 | [train] SSIM: 0.9363 | [valid] PSNR: 33.2836 | [valid] SSIM: 0.9370 | [valid] LPIPS: 0.0589\n",
      "Epoch: 630 | learning rate: 0.000100 | [train] PSNR: 31.9494 | [train] SSIM: 0.9369 | [valid] PSNR: 33.5828 | [valid] SSIM: 0.9333 | [valid] LPIPS: 0.0548\n",
      "Epoch: 681 | learning rate: 0.000100 | [train] PSNR: 32.0572 | [train] SSIM: 0.9366 | [valid] PSNR: 33.8213 | [valid] SSIM: 0.9431 | [valid] LPIPS: 0.0485\n",
      "Epoch: 729 | learning rate: 0.000100 | [train] PSNR: 31.4626 | [train] SSIM: 0.9310 | [valid] PSNR: 32.3253 | [valid] SSIM: 0.9421 | [valid] LPIPS: 0.0464\n",
      "Epoch: 758 | learning rate: 0.000100 | [train] PSNR: 31.3730 | [train] SSIM: 0.9322 | [valid] PSNR: 33.2571 | [valid] SSIM: 0.9453 | [valid] LPIPS: 0.0480\n",
      "Epoch: 810 | learning rate: 0.000050 | [train] PSNR: 31.8451 | [train] SSIM: 0.9326 | [valid] PSNR: 31.8835 | [valid] SSIM: 0.9389 | [valid] LPIPS: 0.0447\n",
      "Epoch: 910 | learning rate: 0.000050 | [train] PSNR: 31.9100 | [train] SSIM: 0.9363 | [valid] PSNR: 31.6168 | [valid] SSIM: 0.9315 | [valid] LPIPS: 0.0598\n",
      "Epoch: 1010 | learning rate: 0.000050 | [train] PSNR: 32.1767 | [train] SSIM: 0.9379 | [valid] PSNR: 32.7379 | [valid] SSIM: 0.9380 | [valid] LPIPS: 0.0490\n",
      "Epoch: 1110 | learning rate: 0.000050 | [train] PSNR: 31.7733 | [train] SSIM: 0.9344 | [valid] PSNR: 31.7889 | [valid] SSIM: 0.9366 | [valid] LPIPS: 0.0541\n",
      "Epoch: 1210 | learning rate: 0.000025 | [train] PSNR: 32.3870 | [train] SSIM: 0.9392 | [valid] PSNR: 32.3821 | [valid] SSIM: 0.9407 | [valid] LPIPS: 0.0553\n",
      "Epoch: 1303 | learning rate: 0.000025 | [train] PSNR: 32.1306 | [train] SSIM: 0.9375 | [valid] PSNR: 32.6511 | [valid] SSIM: 0.9479 | [valid] LPIPS: 0.0446\n",
      "Epoch: 1403 | learning rate: 0.000025 | [train] PSNR: 32.0923 | [train] SSIM: 0.9375 | [valid] PSNR: 31.5221 | [valid] SSIM: 0.9316 | [valid] LPIPS: 0.0556\n",
      "Epoch: 1503 | learning rate: 0.000025 | [train] PSNR: 31.9089 | [train] SSIM: 0.9392 | [valid] PSNR: 31.5352 | [valid] SSIM: 0.9310 | [valid] LPIPS: 0.0626\n",
      "Epoch: 1603 | learning rate: 0.000013 | [train] PSNR: 31.8712 | [train] SSIM: 0.9355 | [valid] PSNR: 32.2559 | [valid] SSIM: 0.9375 | [valid] LPIPS: 0.0567\n",
      "Epoch: 1703 | learning rate: 0.000013 | [train] PSNR: 32.0928 | [train] SSIM: 0.9387 | [valid] PSNR: 31.8725 | [valid] SSIM: 0.9343 | [valid] LPIPS: 0.0606\n",
      "Epoch: 1705 | learning rate: 0.000013 | [train] PSNR: 32.2803 | [train] SSIM: 0.9363 | [valid] PSNR: 34.3151 | [valid] SSIM: 0.9428 | [valid] LPIPS: 0.0516\n",
      "Epoch: 1805 | learning rate: 0.000013 | [train] PSNR: 32.0406 | [train] SSIM: 0.9377 | [valid] PSNR: 32.0451 | [valid] SSIM: 0.9378 | [valid] LPIPS: 0.0520\n",
      "Epoch: 1905 | learning rate: 0.000013 | [train] PSNR: 32.5161 | [train] SSIM: 0.9384 | [valid] PSNR: 31.4702 | [valid] SSIM: 0.9318 | [valid] LPIPS: 0.0603\n"
     ]
    }
   ],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=os.cpu_count()-1)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=16, shuffle=False, num_workers=os.cpu_count()-1)\n",
    "\n",
    "model = torch.compile(ESRGAN(2).to(device))\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = Adam(model.parameters(), lr=2e-4)\n",
    "scheduler = StepLR(optimizer, step_size=400, gamma=0.5)\n",
    "\n",
    "train(model, train_dl, valid_dl, optimizer, scheduler, loss_fn, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cb73da2-3543-4c93-be9e-b3237122aac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('../tmp_model_checkpoints/last.pth')\n",
    "model = ESRGAN(2).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a941793-7027-4738-8160-cf2a0b893c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b717d46-43e2-4eaa-bc36-6c58d3a9d43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d6dc3cd9214090bddde94fae19cb09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e25ec2895aa47c9a461921def1ef08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1675154914e947d0858409ae2ed05f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceba472c38fe4b6f8363cc3866c53f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8874b210441749cdaf2418897c9355e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5928f7a8b8245f78add1e4649f1c100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d41c29150df45ce90574cafdbf36e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PSNR↑</th>\n",
       "      <th>SSIM↑</th>\n",
       "      <th>LPIPS↓</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31px -&gt; 62px</th>\n",
       "      <td>26.755085</td>\n",
       "      <td>0.881284</td>\n",
       "      <td>0.050920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63px -&gt; 126px</th>\n",
       "      <td>28.020311</td>\n",
       "      <td>0.897507</td>\n",
       "      <td>0.074885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127px -&gt; 254px</th>\n",
       "      <td>29.875819</td>\n",
       "      <td>0.920140</td>\n",
       "      <td>0.077094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255px -&gt; 510px</th>\n",
       "      <td>31.448704</td>\n",
       "      <td>0.929568</td>\n",
       "      <td>0.075425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510px -&gt; 1020px</th>\n",
       "      <td>33.369937</td>\n",
       "      <td>0.939958</td>\n",
       "      <td>0.074147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020px -&gt; 2040px</th>\n",
       "      <td>34.640328</td>\n",
       "      <td>0.937814</td>\n",
       "      <td>0.087876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PSNR↑     SSIM↑    LPIPS↓\n",
       "31px -> 62px      26.755085  0.881284  0.050920\n",
       "63px -> 126px     28.020311  0.897507  0.074885\n",
       "127px -> 254px    29.875819  0.920140  0.077094\n",
       "255px -> 510px    31.448704  0.929568  0.075425\n",
       "510px -> 1020px   33.369937  0.939958  0.074147\n",
       "1020px -> 2040px  34.640328  0.937814  0.087876"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = [X32_valid_paths, X16_valid_paths, X8_valid_paths, X4_valid_paths, X2_valid_paths, HR_valid_paths]\n",
    "\n",
    "metrics_x2 = pd.DataFrame(columns=[\"PSNR↑\", \"SSIM↑\", \"LPIPS↓\"])\n",
    "for target_ds in tqdm(targets, total=6):\n",
    "    metrics_x2.loc[len(metrics_x2)] = calc_metrics(model, target_ds, 2)\n",
    "\n",
    "metrics_x2.index = [\n",
    "    \"31px -> 62px\", \"63px -> 126px\", \"127px -> 254px\", \n",
    "    \"255px -> 510px\", \"510px -> 1020px\", \"1020px -> 2040px\"\n",
    "]\n",
    "metrics_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d1fca-32a2-43b3-a6d2-12d32824e497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
